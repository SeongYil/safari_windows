{
    "name": "root",
    "gauges": {
        "WhiteAgent.Policy.Entropy.mean": {
            "value": 0.06608187407255173,
            "min": 2.424655576760415e-05,
            "max": 1.0270227193832397,
            "count": 180
        },
        "WhiteAgent.Policy.Entropy.sum": {
            "value": 3305.944091796875,
            "min": 1.2124247550964355,
            "max": 227099.71875,
            "count": 180
        },
        "WhiteAgent.Environment.EpisodeLength.mean": {
            "value": 15.724506853895019,
            "min": 4.93695832838656,
            "max": 20.88825591586328,
            "count": 180
        },
        "WhiteAgent.Environment.EpisodeLength.sum": {
            "value": 47032.0,
            "min": 41584.0,
            "max": 237598.0,
            "count": 180
        },
        "WhiteAgent.Self-play.ELO.mean": {
            "value": 10500.55771424987,
            "min": 1212.5652594962378,
            "max": 10505.013448155447,
            "count": 180
        },
        "WhiteAgent.Self-play.ELO.sum": {
            "value": 31407168.12332136,
            "min": 5169165.701232461,
            "max": 65792510.00325749,
            "count": 180
        },
        "WhiteAgent.Step.mean": {
            "value": 8999997.0,
            "min": 49991.0,
            "max": 8999997.0,
            "count": 180
        },
        "WhiteAgent.Step.sum": {
            "value": 8999997.0,
            "min": 49991.0,
            "max": 8999997.0,
            "count": 180
        },
        "WhiteAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.23788772523403168,
            "min": -0.5409404039382935,
            "max": 1.2642546892166138,
            "count": 180
        },
        "WhiteAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": -711.2843017578125,
            "min": -1743.450927734375,
            "max": 7144.302734375,
            "count": 180
        },
        "WhiteAgent.Policy.CuriosityValueEstimate.mean": {
            "value": 0.7173125743865967,
            "min": -1.5205819606781006,
            "max": 0.7173125743865967,
            "count": 180
        },
        "WhiteAgent.Policy.CuriosityValueEstimate.sum": {
            "value": 2144.7646484375,
            "min": -4729.1767578125,
            "max": 2144.7646484375,
            "count": 180
        },
        "WhiteAgent.Environment.CumulativeReward.mean": {
            "value": -0.612988308640228,
            "min": -0.997232409911314,
            "max": 1.0407748964200594,
            "count": 180
        },
        "WhiteAgent.Environment.CumulativeReward.sum": {
            "value": -1832.835042834282,
            "min": -3214.080057144165,
            "max": 7348.03015100956,
            "count": 180
        },
        "WhiteAgent.Policy.ExtrinsicReward.mean": {
            "value": -0.612988308640228,
            "min": -0.997232409911314,
            "max": 1.0407748964200594,
            "count": 180
        },
        "WhiteAgent.Policy.ExtrinsicReward.sum": {
            "value": -1832.835042834282,
            "min": -3214.080057144165,
            "max": 7348.03015100956,
            "count": 180
        },
        "WhiteAgent.Policy.CuriosityReward.mean": {
            "value": 5.828940627931621e-05,
            "min": 5.345195216190602e-07,
            "max": 0.029422885230915023,
            "count": 180
        },
        "WhiteAgent.Policy.CuriosityReward.sum": {
            "value": 0.17428532477515546,
            "min": 0.0020557620801469056,
            "max": 125.40033685415983,
            "count": 180
        },
        "WhiteAgent.Losses.PolicyLoss.mean": {
            "value": 0.034522461639911246,
            "min": 0.031089673802489413,
            "max": 0.07181068202153257,
            "count": 180
        },
        "WhiteAgent.Losses.PolicyLoss.sum": {
            "value": 0.10356738491973375,
            "min": 0.06217934760497883,
            "max": 0.14362136404306514,
            "count": 180
        },
        "WhiteAgent.Losses.ValueLoss.mean": {
            "value": 0.2381971186337372,
            "min": 0.001787502781917283,
            "max": 0.5104493822902441,
            "count": 180
        },
        "WhiteAgent.Losses.ValueLoss.sum": {
            "value": 0.7145913559012116,
            "min": 0.003575005563834566,
            "max": 1.0208987645804881,
            "count": 180
        },
        "WhiteAgent.Policy.LearningRate.mean": {
            "value": 3.072490975839333e-05,
            "min": 3.072490975839333e-05,
            "max": 0.000299078085307305,
            "count": 180
        },
        "WhiteAgent.Policy.LearningRate.sum": {
            "value": 9.217472927517997e-05,
            "min": 6.452405849204001e-05,
            "max": 0.0008889315636894798,
            "count": 180
        },
        "WhiteAgent.Policy.Epsilon.mean": {
            "value": 0.11024160666666666,
            "min": 0.11024160666666666,
            "max": 0.19969269500000003,
            "count": 180
        },
        "WhiteAgent.Policy.Epsilon.sum": {
            "value": 0.33072482,
            "min": 0.22150796,
            "max": 0.5963105200000001,
            "count": 180
        },
        "WhiteAgent.Policy.Beta.mean": {
            "value": 0.0005210561726666667,
            "min": 0.0005210561726666667,
            "max": 0.0049846654805,
            "count": 180
        },
        "WhiteAgent.Policy.Beta.sum": {
            "value": 0.0015631685179999999,
            "min": 0.0010932472040000006,
            "max": 0.014815894948000001,
            "count": 180
        },
        "WhiteAgent.Losses.CuriosityForwardLoss.mean": {
            "value": 0.00396784437034512,
            "min": 4.1898297388343055e-05,
            "max": 15.622659499570727,
            "count": 180
        },
        "WhiteAgent.Losses.CuriosityForwardLoss.sum": {
            "value": 0.011903533111035359,
            "min": 0.00012569489216502917,
            "max": 31.245318999141453,
            "count": 180
        },
        "WhiteAgent.Losses.CuriosityInverseLoss.mean": {
            "value": 0.0009132344087068606,
            "min": 1.3958991292639668e-06,
            "max": 2.6459557600319386,
            "count": 180
        },
        "WhiteAgent.Losses.CuriosityInverseLoss.sum": {
            "value": 0.002739703226120582,
            "min": 4.1876973877919e-06,
            "max": 5.291911520063877,
            "count": 180
        },
        "WhiteAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 180
        },
        "WhiteAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 180
        },
        "BlackAgent.Policy.Entropy.mean": {
            "value": 0.0066908299922943115,
            "min": 0.0009465832845307887,
            "max": 0.9489762783050537,
            "count": 892
        },
        "BlackAgent.Policy.Entropy.sum": {
            "value": 67.0421142578125,
            "min": 9.46204662322998,
            "max": 196932.46875,
            "count": 892
        },
        "BlackAgent.Environment.EpisodeLength.mean": {
            "value": 15.457236842105264,
            "min": 5.309343434343434,
            "max": 21.300668151447663,
            "count": 892
        },
        "BlackAgent.Environment.EpisodeLength.sum": {
            "value": 9398.0,
            "min": 8410.0,
            "max": 199702.0,
            "count": 892
        },
        "BlackAgent.Self-play.ELO.mean": {
            "value": 10947.486779189605,
            "min": 1123.8291533241909,
            "max": 11080.457104896655,
            "count": 892
        },
        "BlackAgent.Self-play.ELO.sum": {
            "value": 6656071.96174728,
            "min": 975483.7050853977,
            "max": 11691300.679653011,
            "count": 892
        },
        "BlackAgent.Step.mean": {
            "value": 8919997.0,
            "min": 9995.0,
            "max": 8919997.0,
            "count": 892
        },
        "BlackAgent.Step.sum": {
            "value": 8919997.0,
            "min": 9995.0,
            "max": 8919997.0,
            "count": 892
        },
        "BlackAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.6590310335159302,
            "min": -1.2752846479415894,
            "max": 0.984982430934906,
            "count": 892
        },
        "BlackAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 400.69085693359375,
            "min": -1225.511474609375,
            "max": 1333.0821533203125,
            "count": 892
        },
        "BlackAgent.Policy.CuriosityValueEstimate.mean": {
            "value": 2.1872589588165283,
            "min": -1.1138277053833008,
            "max": 2.4994728565216064,
            "count": 892
        },
        "BlackAgent.Policy.CuriosityValueEstimate.sum": {
            "value": 1329.853515625,
            "min": -964.5748291015625,
            "max": 1568.9849853515625,
            "count": 892
        },
        "BlackAgent.Environment.CumulativeReward.mean": {
            "value": 0.7377796084865144,
            "min": -1.0248064569907613,
            "max": 1.13598555402878,
            "count": 892
        },
        "BlackAgent.Environment.CumulativeReward.sum": {
            "value": 448.5700019598007,
            "min": -1503.3799884319305,
            "max": 1592.0800721645355,
            "count": 892
        },
        "BlackAgent.Policy.ExtrinsicReward.mean": {
            "value": 0.7377796084865144,
            "min": -1.0248064569907613,
            "max": 1.13598555402878,
            "count": 892
        },
        "BlackAgent.Policy.ExtrinsicReward.sum": {
            "value": 448.5700019598007,
            "min": -1503.3799884319305,
            "max": 1592.0800721645355,
            "count": 892
        },
        "BlackAgent.Policy.CuriosityReward.mean": {
            "value": 1.5527058457409065e-05,
            "min": 0.0,
            "max": 0.06943765165561862,
            "count": 892
        },
        "BlackAgent.Policy.CuriosityReward.sum": {
            "value": 0.00944045154210471,
            "min": 0.0,
            "max": 64.29926543310285,
            "count": 892
        },
        "BlackAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 892
        },
        "BlackAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 892
        },
        "BlackAgent.Losses.PolicyLoss.mean": {
            "value": 0.03731929886271246,
            "min": 0.030326936810160986,
            "max": 1.3573448199982523,
            "count": 435
        },
        "BlackAgent.Losses.PolicyLoss.sum": {
            "value": 0.03731929886271246,
            "min": 0.030326936810160986,
            "max": 1.3573448199982523,
            "count": 435
        },
        "BlackAgent.Losses.ValueLoss.mean": {
            "value": 0.05231211221544072,
            "min": 0.00038991015189822066,
            "max": 0.47538366690278056,
            "count": 435
        },
        "BlackAgent.Losses.ValueLoss.sum": {
            "value": 0.05231211221544072,
            "min": 0.00038991015189822066,
            "max": 0.47538366690278056,
            "count": 435
        },
        "BlackAgent.Policy.LearningRate.mean": {
            "value": 3.2557109147660006e-05,
            "min": 3.2557109147660006e-05,
            "max": 0.00029938545020485,
            "count": 435
        },
        "BlackAgent.Policy.LearningRate.sum": {
            "value": 3.2557109147660006e-05,
            "min": 3.2557109147660006e-05,
            "max": 0.00029938545020485,
            "count": 435
        },
        "BlackAgent.Policy.Epsilon.mean": {
            "value": 0.11085234000000002,
            "min": 0.11085234000000002,
            "max": 0.19979514999999998,
            "count": 435
        },
        "BlackAgent.Policy.Epsilon.sum": {
            "value": 0.11085234000000002,
            "min": 0.11085234000000002,
            "max": 0.19979514999999998,
            "count": 435
        },
        "BlackAgent.Policy.Beta.mean": {
            "value": 0.0005515317660000004,
            "min": 0.0005515317660000004,
            "max": 0.004989777985,
            "count": 435
        },
        "BlackAgent.Policy.Beta.sum": {
            "value": 0.0005515317660000004,
            "min": 0.0005515317660000004,
            "max": 0.004989777985,
            "count": 435
        },
        "BlackAgent.Losses.CuriosityForwardLoss.mean": {
            "value": 0.00044410193295334465,
            "min": 5.060636658016371e-06,
            "max": 32.58402545452118,
            "count": 435
        },
        "BlackAgent.Losses.CuriosityForwardLoss.sum": {
            "value": 0.00044410193295334465,
            "min": 5.060636658016371e-06,
            "max": 32.58402545452118,
            "count": 435
        },
        "BlackAgent.Losses.CuriosityInverseLoss.mean": {
            "value": 1.89677706856628e-05,
            "min": 4.288116896233873e-07,
            "max": 2.609393282234669,
            "count": 435
        },
        "BlackAgent.Losses.CuriosityInverseLoss.sum": {
            "value": 1.89677706856628e-05,
            "min": 4.288116896233873e-07,
            "max": 2.609393282234669,
            "count": 435
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1651246301",
        "python_version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\songu\\anaconda3\\Scripts\\mlagents-learn ./safari_test.yaml --env=C:\\Users\\songu\\programmers\\Safari_Proj\\safari_windows\\RL.exe",
        "mlagents_version": "0.28.0",
        "mlagents_envs_version": "0.28.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.8.1",
        "numpy_version": "1.22.3",
        "end_time_seconds": "1651285288"
    },
    "total": 38986.258007000004,
    "count": 1,
    "self": 0.1361442999987048,
    "children": {
        "run_training.setup": {
            "total": 0.33587480000000003,
            "count": 1,
            "self": 0.33587480000000003
        },
        "TrainerController.start_learning": {
            "total": 38985.7859879,
            "count": 1,
            "self": 54.31609900030162,
            "children": {
                "TrainerController._reset_env": {
                    "total": 4.100278700017345,
                    "count": 90,
                    "self": 4.100278700017345
                },
                "TrainerController.advance": {
                    "total": 38927.140828199685,
                    "count": 2410682,
                    "self": 63.85172269990289,
                    "children": {
                        "env_step": {
                            "total": 25248.642004202175,
                            "count": 2410682,
                            "self": 21345.159402707854,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 3869.7520773986776,
                                    "count": 2410682,
                                    "self": 162.0755358033498,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 3707.6765415953278,
                                            "count": 2988536,
                                            "self": 664.9833405952609,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 3042.693201000067,
                                                    "count": 2988536,
                                                    "self": 3042.693201000067
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 33.7305240956419,
                                    "count": 2410681,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 38912.349686800335,
                                            "count": 2410681,
                                            "is_parallel": true,
                                            "self": 21076.31363690189,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.31864410001073873,
                                                    "count": 180,
                                                    "is_parallel": true,
                                                    "self": 0.2971418000201136,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.02150229999062514,
                                                            "count": 360,
                                                            "is_parallel": true,
                                                            "self": 0.02150229999062514
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 17835.717405798434,
                                                    "count": 2410681,
                                                    "is_parallel": true,
                                                    "self": 640.6841118992925,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 479.56457560171145,
                                                            "count": 2410681,
                                                            "is_parallel": true,
                                                            "self": 479.56457560171145
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 11041.85983319961,
                                                            "count": 2410681,
                                                            "is_parallel": true,
                                                            "self": 11041.85983319961
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 5673.608885097818,
                                                            "count": 4821362,
                                                            "is_parallel": true,
                                                            "self": 5192.212631992894,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 481.39625310492414,
                                                                    "count": 9642724,
                                                                    "is_parallel": true,
                                                                    "self": 481.39625310492414
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 13614.647101297609,
                            "count": 4821362,
                            "self": 281.7468165980008,
                            "children": {
                                "process_trajectory": {
                                    "total": 3824.5690636996846,
                                    "count": 4821362,
                                    "self": 3824.317857499686,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.2512061999987054,
                                            "count": 2,
                                            "self": 0.2512061999987054
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 9508.331220999924,
                                    "count": 874,
                                    "self": 3398.6621987002673,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 6109.669022299657,
                                            "count": 139840,
                                            "self": 6109.669022299657
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.3999961083754897e-06,
                    "count": 1,
                    "self": 1.3999961083754897e-06
                },
                "TrainerController._save_models": {
                    "total": 0.22878060000221012,
                    "count": 1,
                    "self": 0.005620300005830359,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.22316029999637976,
                            "count": 2,
                            "self": 0.22316029999637976
                        }
                    }
                }
            }
        }
    }
}